# ğŸ¤– Sentry-AI - Cognitive Automation Agent for macOS

**Version:** 1.0.0  
**Status:** ğŸš§ In Development  
**License:** MIT

> **Un agent d'automatisation cognitive qui observe, comprend et agit sur votre environnement macOS de maniÃ¨re intelligente et sÃ©curisÃ©e.**

---

## ğŸŒŸ Vision du Projet

Sentry-AI est un agent d'intelligence artificielle conÃ§u pour automatiser les tÃ¢ches rÃ©pÃ©titives sur macOS en observant l'interface utilisateur, en comprenant le contexte grÃ¢ce Ã  un modÃ¨le de langage local, et en prenant des dÃ©cisions intelligentes pour agir en votre nom. Contrairement aux solutions traditionnelles d'automatisation, Sentry-AI combine la puissance des API natives d'Apple avec l'intelligence des LLMs pour offrir une expÃ©rience d'automatisation vÃ©ritablement cognitive.

### Pourquoi Sentry-AI ?

Les utilisateurs de macOS sont constamment interrompus par des boÃ®tes de dialogue demandant des confirmations simples : "Voulez-vous enregistrer ?", "Autoriser cette mise Ã  jour ?", "Fermer sans enregistrer ?". Ces interruptions, bien que nÃ©cessaires, brisent le flux de travail et rÃ©duisent la productivitÃ©. Sentry-AI rÃ©sout ce problÃ¨me en :

*   **Observant** continuellement votre environnement de travail
*   **Comprenant** le contexte de chaque dialogue ou notification
*   **DÃ©cidant** de la meilleure action Ã  entreprendre en fonction de vos prÃ©fÃ©rences
*   **Agissant** automatiquement pour vous, tout en respectant votre sÃ©curitÃ© et votre vie privÃ©e

---

## âœ¨ CaractÃ©ristiques Principales

### ğŸ”’ ConfidentialitÃ© Absolue

*   **100% Local :** Toutes les donnÃ©es (captures d'Ã©cran, textes, dÃ©cisions) sont traitÃ©es localement sur votre Mac.
*   **Aucune Connexion Cloud :** Utilisation exclusive de modÃ¨les d'IA locaux via Ollama.
*   **ContrÃ´le Total :** Vous dÃ©cidez quelles applications peuvent Ãªtre automatisÃ©es.

### âš¡ Performance OptimisÃ©e

*   **Native macOS :** Utilise les API d'accessibilitÃ© natives pour une intÃ©gration parfaite.
*   **Apple Silicon Ready :** OptimisÃ© pour les puces M1/M2/M3/M4 avec Neural Engine.
*   **Faible Impact :** Architecture Ã©vÃ©nementielle pour minimiser l'utilisation du CPU et de la batterie.

### ğŸ§  Intelligence Contextuelle

*   **DÃ©cisions Ã‰clairÃ©es :** Le LLM local analyse le contexte complet (application, historique, prÃ©fÃ©rences) avant d'agir.
*   **Apprentissage des PrÃ©fÃ©rences :** Le systÃ¨me s'amÃ©liore au fil du temps en apprenant vos choix.
*   **RÃ¨gles Personnalisables :** DÃ©finissez des rÃ¨gles spÃ©cifiques pour diffÃ©rentes applications ou situations.

### ğŸ›¡ï¸ SÃ©curitÃ© RenforcÃ©e

*   **Liste Blanche/Noire :** Excluez automatiquement les applications sensibles (Terminal, Keychain, etc.).
*   **Journalisation ComplÃ¨te :** Toutes les actions sont enregistrÃ©es pour audit et transparence.
*   **Mode Confirmation :** PossibilitÃ© de demander confirmation avant certaines actions critiques.

---

## ğŸ—ï¸ Architecture

Sentry-AI est construit autour de quatre modules principaux :

| Module | ResponsabilitÃ© |
| :--- | :--- |
| **Observer** | Surveille l'interface utilisateur via l'API d'accessibilitÃ© macOS |
| **Analyzer** | Extrait le contexte et analyse les dialogues (avec fallback OCR) |
| **Decision Engine** | Interroge le LLM local (Ollama) pour prendre une dÃ©cision |
| **Actor** | ExÃ©cute l'action dÃ©cidÃ©e de maniÃ¨re programmatique |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Observer  â”‚â”€â”€â”€â”€â”€â–¶â”‚   Analyzer   â”‚â”€â”€â”€â”€â”€â–¶â”‚ Decision Engine â”‚â”€â”€â”€â”€â”€â–¶â”‚  Actor   â”‚
â”‚ (UI Watch)  â”‚      â”‚  (Context)   â”‚      â”‚   (AI/LLM)      â”‚      â”‚ (Action) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                       â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                 â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                 â”‚ Core Serviceâ”‚
                                 â”‚ (FastAPI)   â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Pour plus de dÃ©tails, consultez [PROJECT_PLAN.md](PROJECT_PLAN.md).

---

## ğŸš€ Installation

### Installation Automatique (RecommandÃ©e)

Utilisez le script d'installation automatique :

```bash
git clone https://github.com/lekesiz/Sentry-AI.git
cd Sentry-AI
./setup.sh
```

Le script va :
- âœ“ CrÃ©er un environnement virtuel Python
- âœ“ Installer toutes les dÃ©pendances
- âœ“ VÃ©rifier l'installation d'Ollama
- âœ“ Configurer le fichier `.env`
- âœ“ Tester l'installation

Ensuite, suivez les instructions affichÃ©es pour :
1. DÃ©marrer Ollama (`ollama serve`)
2. TÃ©lÃ©charger le modÃ¨le (`ollama pull phi3:mini`)
3. Accorder les permissions d'accessibilitÃ©
4. Lancer Sentry-AI (`make run`)

### Installation Manuelle

Si vous prÃ©fÃ©rez installer manuellement :

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/lekesiz/Sentry-AI.git
cd Sentry-AI

# 2. CrÃ©er un environnement virtuel
python3.11 -m venv venv
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Installer Ollama et tÃ©lÃ©charger un modÃ¨le
brew install ollama
ollama serve  # Dans un terminal sÃ©parÃ©
ollama pull phi3:mini

# 5. Copier le fichier de configuration
cp .env.example .env

# 6. Tester l'installation
python test_installation.py

# 7. Lancer Sentry-AI
make run
```

### PrÃ©requis

*   **macOS 13.0+** (Ventura ou supÃ©rieur)
*   **Python 3.11+**
*   **Ollama** installÃ© ([ollama.ai](https://ollama.ai))
*   **Permissions d'accessibilitÃ©** (l'application vous guidera)

---

## ğŸ“– Documentation

*   [Plan de Projet et Architecture](PROJECT_PLAN.md)
*   [Documentation API](docs/api.md) *(Ã  venir)*
*   [Guide de Contribution](CONTRIBUTING.md) *(Ã  venir)*

---

## ğŸ›£ï¸ Roadmap

### âœ… Milestone 1 : Fondations (En cours)

*   [x] Structure du projet
*   [x] Documentation initiale
*   [ ] Module Observer (Accessibility API)
*   [ ] Module Analyzer (contexte + OCR)
*   [ ] Module Decision Engine (Ollama)
*   [ ] Module Actor (automation)
*   [ ] Tests unitaires

### ğŸ”œ Milestone 2 : Robustesse

*   [ ] Gestion d'erreurs avancÃ©e
*   [ ] SystÃ¨me de logs avec SQLite
*   [ ] Liste blanche/noire d'applications
*   [ ] Optimisation performance

### ğŸ”® Milestone 3 : Interface Utilisateur

*   [ ] Application de barre de menus
*   [ ] Visualisation des logs en temps rÃ©el
*   [ ] Configuration des prÃ©fÃ©rences
*   [ ] Statistiques d'utilisation

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Ce projet suit une mÃ©thodologie inspirÃ©e de [Yago](https://github.com/lekesiz/yago) avec une emphase sur la qualitÃ© du code, la documentation et les tests.

### Principes de DÃ©veloppement

*   **Privacy First :** Aucune donnÃ©e ne doit quitter la machine de l'utilisateur.
*   **Safety First :** Toujours privilÃ©gier la sÃ©curitÃ© de l'utilisateur.
*   **Transparency :** Chaque action doit Ãªtre loggÃ©e et auditable.
*   **Testability :** Chaque module doit Ãªtre testable de maniÃ¨re isolÃ©e.

---

## ğŸ“ License

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

*   InspirÃ© par le projet [Yago](https://github.com/lekesiz/yago) pour sa structure professionnelle
*   BasÃ© sur les concepts d'automatisation cognitive dÃ©crits dans [ce document](https://github.com/lekesiz/Sentry-AI)
*   Utilise [Ollama](https://ollama.ai) pour l'exÃ©cution locale de LLMs
*   S'appuie sur les frameworks natifs d'Apple (Accessibility, Vision)

---

**DÃ©veloppÃ© avec â¤ï¸ pour la communautÃ© macOS**
